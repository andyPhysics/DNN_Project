{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "\n",
    "def load_files(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in batch:\n",
    "        print('Loading File: ' + i)\n",
    "        x = np.load(i,encoding = 'latin1',allow_pickle=True).item()\n",
    "        keys = x.keys()\n",
    "        for key in keys:\n",
    "            images.append(x[key][0])\n",
    "            labels.append(x[key][1])\n",
    "    return np.array(images),np.array(labels)\n",
    "\n",
    "def get_feature(labels,feature):\n",
    "    feature_values = []\n",
    "    for i in labels:\n",
    "        feature_values.append(i[feature])\n",
    "    feature_values = np.array(feature_values)\n",
    "    return feature_values\n",
    "\n",
    "def get_cos_values(zenith,azimuth):\n",
    "    cos1 = []\n",
    "    cos2 = []\n",
    "    cos3 = []\n",
    "    for i,j in zip(zenith,azimuth):\n",
    "        cos1.append(np.sin(i) * np.cos(j))\n",
    "        cos2.append(np.sin(i) * np.sin(j))\n",
    "        cos3.append(np.cos(i))\n",
    "    return np.array(cos1),np.array(cos2),np.array(cos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/fs/scratch/PAS1495/amedina/'\n",
    "y = os.listdir(file_path+'processed_simple')\n",
    "\n",
    "file_names = []\n",
    "\n",
    "for i in y:\n",
    "    file_names.append(file_path+'processed_simple/'+i)\n",
    "\n",
    "file_names_batched = list(np.array_split(file_names,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_5958.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_207.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_5774.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_5256.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_4768.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_2519.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_4632.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_5356.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_4155.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_5633.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_4163.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_7039.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_6819.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_3831.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_2088.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_1612.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_7526.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_3090.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_2302.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_678.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_3597.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_6632.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_2323.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_3310.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_7225.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_6125.npy\n",
      "Loading File: /fs/scratch/PAS1495/amedina/processed_simple/images_6204.npy\n"
     ]
    }
   ],
   "source": [
    "images1,labels = load_files(file_names_batched[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images1[:,:,:,:]\n",
    "#images = images1\n",
    "\n",
    "\n",
    "zenith_values = get_feature(labels,1)\n",
    "azimuth_values = get_feature(labels,2)\n",
    "\n",
    "zenith_direction = []\n",
    "\n",
    "for i in zenith_values:\n",
    "    if i < np.pi/2.0:\n",
    "        zenith_direction.append(0)\n",
    "    if i >= np.pi/2.0:\n",
    "        zenith_direction.append(1)\n",
    "\n",
    "cos1,cos2,cos3 = get_cos_values(zenith_values,azimuth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,load_model, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input,InputLayer, Concatenate\n",
    "from keras.layers import SeparableConv2D, MaxPooling2D , GaussianNoise,BatchNormalization\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from keras.layers import LeakyReLU,GaussianDropout,Lambda,UpSampling1D, LSTM\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60534236 0.01458017 0.44281103]\n",
      " [0.12694781 0.79961908 0.64512226]\n",
      " [0.82456251 0.27577657 0.80721822]\n",
      " ...\n",
      " [0.05406233 0.32880662 0.64775798]\n",
      " [0.33655306 0.92165617 0.7132866 ]\n",
      " [0.69700136 0.94558757 0.38756254]]\n"
     ]
    }
   ],
   "source": [
    "cos_values = np.array(list(zip(cos1,cos2,cos3)))\n",
    "cos_values1 = np.zeros([len(cos_values),len(cos_values[0])])\n",
    "for i in range(len(cos_values)):\n",
    "    for j in range(len(cos_values[0])):\n",
    "        cos_values1[i][j]=(cos_values[i][j] + 1.0)/2.0\n",
    "print(cos_values1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(images,values):\n",
    "    x_train, x_test , y_train , y_test = train_test_split(np.array(zip(images,zenith_direction)),values,test_size = 0.1 , random_state=42)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train,x_test,y_train,y_test = get_data(images,cos_values1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_space_angle(y_true,y_pred):\n",
    "    y_true1 = y_true*2.0-1.0\n",
    "    y_pred1 = y_pred*2.0-1.0\n",
    "    subtraction = tf.math.subtract(y_true1,y_pred1)\n",
    "    y = tf.matrix_diag_part(K.dot(subtraction,K.transpose(subtraction)))\n",
    "    loss = tf.math.reduce_mean(y)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 13:45:13.505906 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 13:45:13.521400 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 13:45:13.525424 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0819 13:45:13.526942 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0819 13:45:13.528426 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0819 13:45:13.536658 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0819 13:45:13.630880 47692769695040 deprecation_wrapper.py:119] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 60, 86)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 9, 60, 86)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 9, 30, 43)    0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 32, 30, 43)   401         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 30, 43)   0           separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 15, 22)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 32, 15, 22)   1344        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 15, 22)   0           separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 8, 11)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 32, 8, 11)    1344        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 46440)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2816)         0           separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 11610)        0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 10560)        0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2816)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 74242)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,089\n",
      "Trainable params: 3,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "number_features = 9\n",
    "\n",
    "img_heights,img_rows = 60,86\n",
    "\n",
    "kernel = 3\n",
    "kernel2 = 2\n",
    "\n",
    "model1_input = Input(shape=(number_features,img_heights,img_rows))\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1_input)\n",
    "output1 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output1)\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1)\n",
    "output2 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output2)\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1)\n",
    "output3 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output3)\n",
    "\n",
    "cnn_model1 = Flatten()(model1_input)\n",
    "cnn_model2 = Flatten()(model1)\n",
    "cnn_model3 = Flatten()(output1)\n",
    "cnn_model4 = Flatten()(output2)\n",
    "cnn_model5 = Flatten()(output3)\n",
    "cnn_model = Concatenate(axis=-1)([cnn_model1,\n",
    "                                cnn_model2,\n",
    "                                cnn_model3,\n",
    "                                cnn_model4,\n",
    "                                cnn_model5\n",
    "                                ])\n",
    "\n",
    "\n",
    "cnn_model = Model(inputs=model1_input,outputs=cnn_model)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=1e-5, amsgrad=False)\n",
    "cnn_model.compile(optimizer=opt , loss = loss_space_angle)\n",
    "\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 13:45:13.862879 47692769695040 deprecation.py:323] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 979 samples, validate on 109 samples\n",
      "Epoch 1/40\n",
      "979/979 [==============================] - 1s 1ms/step - loss: 0.4873 - val_loss: 0.3290\n",
      "Epoch 2/40\n",
      "979/979 [==============================] - 1s 690us/step - loss: 0.3631 - val_loss: 0.3274\n",
      "Epoch 3/40\n",
      "979/979 [==============================] - 1s 702us/step - loss: 0.3605 - val_loss: 0.3126\n",
      "Epoch 4/40\n",
      "979/979 [==============================] - 1s 704us/step - loss: 0.3301 - val_loss: 0.2896\n",
      "Epoch 5/40\n",
      "979/979 [==============================] - 1s 730us/step - loss: 0.3065 - val_loss: 0.2844\n",
      "Epoch 6/40\n",
      "979/979 [==============================] - 1s 714us/step - loss: 0.2929 - val_loss: 0.2746\n",
      "Epoch 7/40\n",
      "979/979 [==============================] - 1s 738us/step - loss: 0.2761 - val_loss: 0.2653\n",
      "Epoch 8/40\n",
      "979/979 [==============================] - 1s 720us/step - loss: 0.2622 - val_loss: 0.2589\n",
      "Epoch 9/40\n",
      "979/979 [==============================] - 1s 730us/step - loss: 0.2497 - val_loss: 0.2525\n",
      "Epoch 10/40\n",
      "979/979 [==============================] - 1s 714us/step - loss: 0.2370 - val_loss: 0.2458\n",
      "Epoch 11/40\n",
      "979/979 [==============================] - 1s 716us/step - loss: 0.2254 - val_loss: 0.2392\n",
      "Epoch 12/40\n",
      "979/979 [==============================] - 1s 716us/step - loss: 0.2151 - val_loss: 0.2339\n",
      "Epoch 13/40\n",
      "979/979 [==============================] - 1s 727us/step - loss: 0.2049 - val_loss: 0.2293\n",
      "Epoch 14/40\n",
      "979/979 [==============================] - 1s 702us/step - loss: 0.1950 - val_loss: 0.2241\n",
      "Epoch 15/40\n",
      "979/979 [==============================] - 1s 731us/step - loss: 0.1862 - val_loss: 0.2183\n",
      "Epoch 16/40\n",
      "979/979 [==============================] - 1s 719us/step - loss: 0.1778 - val_loss: 0.2113\n",
      "Epoch 17/40\n",
      "979/979 [==============================] - 1s 701us/step - loss: 0.1697 - val_loss: 0.2062\n",
      "Epoch 18/40\n",
      "979/979 [==============================] - 1s 727us/step - loss: 0.1620 - val_loss: 0.2013\n",
      "Epoch 19/40\n",
      "979/979 [==============================] - 1s 715us/step - loss: 0.1551 - val_loss: 0.1964\n",
      "Epoch 20/40\n",
      "979/979 [==============================] - 1s 723us/step - loss: 0.1487 - val_loss: 0.1899\n",
      "Epoch 21/40\n",
      "979/979 [==============================] - 1s 720us/step - loss: 0.1418 - val_loss: 0.1862\n",
      "Epoch 22/40\n",
      "979/979 [==============================] - 1s 715us/step - loss: 0.1358 - val_loss: 0.1815\n",
      "Epoch 23/40\n",
      "979/979 [==============================] - 1s 700us/step - loss: 0.1305 - val_loss: 0.1756\n",
      "Epoch 24/40\n",
      "979/979 [==============================] - 1s 714us/step - loss: 0.1250 - val_loss: 0.1712\n",
      "Epoch 25/40\n",
      "979/979 [==============================] - 1s 700us/step - loss: 0.1202 - val_loss: 0.1676\n",
      "Epoch 26/40\n",
      "979/979 [==============================] - 1s 710us/step - loss: 0.1152 - val_loss: 0.1619\n",
      "Epoch 27/40\n",
      "979/979 [==============================] - 1s 703us/step - loss: 0.1106 - val_loss: 0.1572\n",
      "Epoch 28/40\n",
      "979/979 [==============================] - 1s 710us/step - loss: 0.1065 - val_loss: 0.1531\n",
      "Epoch 29/40\n",
      "979/979 [==============================] - 1s 706us/step - loss: 0.1024 - val_loss: 0.1503\n",
      "Epoch 30/40\n",
      "979/979 [==============================] - 1s 705us/step - loss: 0.0985 - val_loss: 0.1463\n",
      "Epoch 31/40\n",
      "979/979 [==============================] - 1s 664us/step - loss: 0.0949 - val_loss: 0.1420\n",
      "Epoch 32/40\n",
      "979/979 [==============================] - 1s 703us/step - loss: 0.0916 - val_loss: 0.1379\n",
      "Epoch 33/40\n",
      "979/979 [==============================] - 1s 696us/step - loss: 0.0882 - val_loss: 0.1360\n",
      "Epoch 34/40\n",
      "979/979 [==============================] - 1s 679us/step - loss: 0.0851 - val_loss: 0.1321\n",
      "Epoch 35/40\n",
      "979/979 [==============================] - 1s 710us/step - loss: 0.0820 - val_loss: 0.1275\n",
      "Epoch 36/40\n",
      "979/979 [==============================] - 1s 710us/step - loss: 0.0794 - val_loss: 0.1234\n",
      "Epoch 37/40\n",
      "979/979 [==============================] - 1s 714us/step - loss: 0.0767 - val_loss: 0.1210\n",
      "Epoch 38/40\n",
      "979/979 [==============================] - 1s 701us/step - loss: 0.0742 - val_loss: 0.1161\n",
      "Epoch 39/40\n",
      "979/979 [==============================] - 1s 713us/step - loss: 0.0717 - val_loss: 0.1129\n",
      "Epoch 40/40\n",
      "979/979 [==============================] - 1s 679us/step - loss: 0.0694 - val_loss: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b617925d250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs=40\n",
    "\n",
    "model1_input = Input(shape=(number_features,img_heights,img_rows))\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1_input)\n",
    "output1 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output1)\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1)\n",
    "output2 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output2)\n",
    "\n",
    "model1 = LeakyReLU(alpha = 0.01)(model1)\n",
    "output3 = MaxPooling2D(kernel2,padding='same',data_format='channels_first')(model1)\n",
    "model1 = SeparableConv2D(32,kernel,padding='same',kernel_regularizer=regularizers.l2(0.01),data_format='channels_first')(output3)\n",
    "\n",
    "cnn_model1 = Flatten()(model1_input)\n",
    "cnn_model2 = Flatten()(model1)\n",
    "cnn_model3 = Flatten()(output1)\n",
    "cnn_model4 = Flatten()(output2)\n",
    "cnn_model5 = Flatten()(output3)\n",
    "direction_model = Concatenate(axis=-1)([cnn_model1,\n",
    "                                cnn_model2,\n",
    "                                cnn_model3,\n",
    "                                cnn_model4,\n",
    "                                cnn_model5\n",
    "                                ])\n",
    "\n",
    "prediction = Dense(1,activation='sigmoid')(direction_model)\n",
    "\n",
    "\n",
    "direction_model = Model(inputs=model1_input,outputs=prediction)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=1e-5, amsgrad=False)\n",
    "direction_model.compile(optimizer=opt , loss = 'binary_crossentropy')\n",
    "\n",
    "direction_model.fit(np.array(zip(*x_train)[0]), np.array(zip(*x_train)[1]),\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(np.array(zip(*x_test)[0]), np.array(zip(*x_test)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 13:45:42.986244 47692769695040 deprecation.py:506] From /users/PAS1495/amedina/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 9, 60, 86)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 74242)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 74242)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 74243)        0           dropout_1[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          38012928    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 46440)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 46952)        0           leaky_re_lu_8[0][0]              \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            140859      concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 38,416,443\n",
      "Trainable params: 38,416,443\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_new = Input(shape=(number_features,img_heights,img_rows))\n",
    "\n",
    "input_value = Input(shape=(1,))\n",
    "\n",
    "output = Lambda(lambda x: cnn_model(x))(input_new)\n",
    "\n",
    "model = Dropout(0.5)(output)\n",
    "model = Concatenate()([model,input_value])\n",
    "model = Dense(512)(model)\n",
    "model = LeakyReLU(alpha = 0.01)(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(512)(model)\n",
    "model = LeakyReLU(alpha = 0.01)(model)\n",
    "\n",
    "input_new_prime = Flatten()(input_new)\n",
    "model = Concatenate(axis=-1)([model, input_new_prime])\n",
    "\n",
    "predictions = Dense(3)(model)\n",
    "\n",
    "model = Model(inputs=[input_new,input_value],outputs=predictions)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=1e-5, amsgrad=False)\n",
    "model.compile(optimizer=opt , loss = loss_space_angle)\n",
    "\n",
    "print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 9, 60, 86)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keras.utils.plot_model(cnn_model, to_file='cnn_model.png', show_shapes=False, show_layer_names=True, rankdir='TB')\n",
    "#keras.utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB')\n",
    "np.array(zip(*x_train)[0]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 979 samples, validate on 109 samples\n",
      "Epoch 1/40\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.5940 - val_loss: 1.3547\n",
      "Epoch 2/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.2997 - val_loss: 1.1513\n",
      "Epoch 3/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.9860 - val_loss: 0.9587\n",
      "Epoch 4/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.7627 - val_loss: 0.8434\n",
      "Epoch 5/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.5856 - val_loss: 0.7057\n",
      "Epoch 6/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.4517 - val_loss: 0.5655\n",
      "Epoch 7/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.3418 - val_loss: 0.4882\n",
      "Epoch 8/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.2551 - val_loss: 0.3855\n",
      "Epoch 9/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.1970 - val_loss: 0.3245\n",
      "Epoch 10/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.1533 - val_loss: 0.2678\n",
      "Epoch 11/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.1204 - val_loss: 0.2435\n",
      "Epoch 12/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.1001 - val_loss: 0.2190\n",
      "Epoch 13/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0811 - val_loss: 0.1853\n",
      "Epoch 14/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0683 - val_loss: 0.1604\n",
      "Epoch 15/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0600 - val_loss: 0.1393\n",
      "Epoch 16/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0497 - val_loss: 0.1360\n",
      "Epoch 17/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0461 - val_loss: 0.1236\n",
      "Epoch 18/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0424 - val_loss: 0.1133\n",
      "Epoch 19/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0378 - val_loss: 0.1120\n",
      "Epoch 20/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0341 - val_loss: 0.1062\n",
      "Epoch 21/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0311 - val_loss: 0.1036\n",
      "Epoch 22/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0279 - val_loss: 0.0988\n",
      "Epoch 23/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0278 - val_loss: 0.0962\n",
      "Epoch 24/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0255 - val_loss: 0.0925\n",
      "Epoch 25/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0239 - val_loss: 0.0880\n",
      "Epoch 26/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0229 - val_loss: 0.0929\n",
      "Epoch 27/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0209 - val_loss: 0.0863\n",
      "Epoch 28/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0199 - val_loss: 0.0855\n",
      "Epoch 29/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0206 - val_loss: 0.0876\n",
      "Epoch 30/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0180 - val_loss: 0.0880\n",
      "Epoch 31/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0177 - val_loss: 0.0860\n",
      "Epoch 32/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0180 - val_loss: 0.0860\n",
      "Epoch 33/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0177 - val_loss: 0.0845\n",
      "Epoch 34/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0165 - val_loss: 0.0842\n",
      "Epoch 35/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0157 - val_loss: 0.0826\n",
      "Epoch 36/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0152 - val_loss: 0.0826\n",
      "Epoch 37/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0145 - val_loss: 0.0839\n",
      "Epoch 38/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0136 - val_loss: 0.0865\n",
      "Epoch 39/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0142 - val_loss: 0.0851\n",
      "Epoch 40/40\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 0.0145 - val_loss: 0.0886\n"
     ]
    }
   ],
   "source": [
    "history1 = []\n",
    "history2 = []\n",
    "batch_size = 128\n",
    "epochs=40\n",
    "\n",
    "\n",
    "history=model.fit([np.array(zip(*x_train)[0]),np.array(zip(*x_train)[1])], y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=([np.array(zip(*x_test)[0]),np.array(zip(*x_test)[1])], y_test))\n",
    "history_dict = history.history\n",
    "history1.append(history_dict['loss'])\n",
    "history2.append(history_dict['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#history_dict = history.history\n",
    "#print(history_dict.keys())\n",
    "#loss_values = history_dict['loss']\n",
    "#val_loss_values = history_dict['val_loss']\n",
    "\n",
    "#epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "#start = 2\n",
    "\n",
    "#plt.plot(epochs[start:len(epochs)],loss_values[start:len(loss_values)],'bo',label='Training loss')\n",
    "#plt.plot(epochs[start:len(epochs)],val_loss_values[start:len(val_loss_values)],'b',label='Validation loss')\n",
    "#plt.title('Training and validation loss')\n",
    "#plt.xlabel('Epochs')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.legend()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = ['128']\n",
    "count = 0\n",
    "count1 = 0\n",
    "epochs = range(1, len(history1[0])+1)\n",
    "plt.figure()\n",
    "for i in history1:\n",
    "    plt.plot(epochs,i,label = labels[count])\n",
    "    count+=1\n",
    "for j in history2:\n",
    "    plt.plot(epochs,j,label=labels[count1])\n",
    "    count1+=1\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.savefig('figure.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Conda 5.2) [python/2.7-conda5.2]",
   "language": "python",
   "name": "sys_python27conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
